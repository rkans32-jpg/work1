from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import pandas as pd
import time

base_url = "https://www.fsc.go.kr/no010102"
data = []

# Selenium ì˜µì…˜ ì„¤ì •
options = webdriver.ChromeOptions()
options.add_argument("--headless")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("lang=ko_KR")
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36")

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# 1~10í˜ì´ì§€ ë°˜ë³µ
for page in range(1, 11):
    url = f"{base_url}?page={page}"
    driver.get(url)
    time.sleep(2.5)

    soup = BeautifulSoup(driver.page_source, "html.parser")
    
    # ë¶€ëª¨ ul selectorë¡œ ì ‘ê·¼
    ul = soup.select_one("#container > div.content-body > div > div.board-list-wrap > ul")
    if not ul:
        print(f"{page}í˜ì´ì§€ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        continue

    items = ul.select("li")  # ul í•˜ìœ„ li ëª¨ë‘ ì„ íƒ

    for item in items:
        a_tag = item.select_one("div.cont > div.subject > a")
        if not a_tag:
            continue

        title = a_tag.get_text(strip=True)
        link = urljoin(base_url, a_tag.get("href"))

        date_tag = item.select_one("div.other-info > span.date")
        date = date_tag.get_text(strip=True) if date_tag else "ë‚ ì§œì—†ìŒ"

        data.append({
            "ë‚ ì§œ": date,
            "ì œëª©": title,
            "ë§í¬": link
        })

    print(f"{page}í˜ì´ì§€ ì™„ë£Œ")

driver.quit()

df = pd.DataFrame(data)

if not df.empty:
    df.to_excel("ê¸ˆìœµìœ„_ë³´ë„ìë£Œ_ìŠ¤í¬ë˜í•‘.xlsx", index=False)
    print("ğŸ“ 'ê¸ˆìœµìœ„_ë³´ë„ìë£Œ_ìŠ¤í¬ë˜í•‘.xlsx' ì €ì¥ ì™„ë£Œ")
else:
    print("â— ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ì–´ ì—‘ì…€ë¡œ ì €ì¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
